{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "083e4aeb",
   "metadata": {},
   "source": [
    "# Breast Cancer Detection - Wisconsin Breast Cancer Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fcaf88",
   "metadata": {},
   "source": [
    "#### Project Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff63c42",
   "metadata": {},
   "source": [
    "Breast cancer is the most common cancer amongst women in the world. It accounts for 25% of all cancer cases, and affected over 2.1 Million people in 2015 alone. It starts when cells in the breast begin to grow out of control. These cells usually form tumors that can be seen via X-ray or felt as lumps in the breast area.\n",
    "\n",
    "The key challenges against it’s detection is how to classify tumors into malignant (cancerous) or benign (non cancerous)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6e7e6d",
   "metadata": {},
   "source": [
    "### 1. Importing the libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5deab4d",
   "metadata": {},
   "source": [
    "A Python library is a collection of related modules. It contains bundles of code that can be used repeatedly in different programs. It makes Python Programming simpler and convenient for the programmer. As we don't need to write the same code again and again for different programs.\n",
    "\n",
    "In this notebook, we will be using the following libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ae26256",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Wrangling \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import missingno\n",
    "from collections import Counter\n",
    "from collections import OrderedDict\n",
    "\n",
    "### Data Visualization\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "### Modelling \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "### Tabulating the results\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "### Model Validation\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "### Remove unnecessary warnings\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09cf9eb",
   "metadata": {},
   "source": [
    "### 2. Importing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198ad2d9",
   "metadata": {},
   "source": [
    "This data was donated by researchers of the University of Wisconsin and includes the measurements from digitized images of fine-needle aspirate of a breast mass.\n",
    "\n",
    "The breast cancer data includes 569 examples of cancer biopsies, each with 32 features. One feature is an identification number, another is the cancer diagnosis and 30 are numeric-valued laboratory measurements.\n",
    "The diagnosis is coded as \"M\" to indicate malignant or \"B\" to indicate benign.\n",
    "\n",
    "The other 30 numeric measurements comprise the mean, standard error and worst (i.e. largest) value for 10 different characteristics of the digitized cell nuclei, which are as follows:-\n",
    "\n",
    "1. Radius\n",
    "2. Texture\n",
    "3. Perimeter\n",
    "4. Area\n",
    "5. Smoothness\n",
    "6. Compactness\n",
    "7. Concavity\n",
    "8. Concave Points\n",
    "9. Symmetry\n",
    "10. Fractal dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e5e7ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fetching the dataset\n",
    "\n",
    "dataset = pd.read_csv('../Datasets/breast-cancer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "416eac93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>843786</td>\n",
       "      <td>M</td>\n",
       "      <td>12.45</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.15780</td>\n",
       "      <td>0.08089</td>\n",
       "      <td>...</td>\n",
       "      <td>15.47</td>\n",
       "      <td>23.75</td>\n",
       "      <td>103.40</td>\n",
       "      <td>741.6</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.5249</td>\n",
       "      <td>0.5355</td>\n",
       "      <td>0.1741</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.12440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>844359</td>\n",
       "      <td>M</td>\n",
       "      <td>18.25</td>\n",
       "      <td>19.98</td>\n",
       "      <td>119.60</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>0.09463</td>\n",
       "      <td>0.10900</td>\n",
       "      <td>0.11270</td>\n",
       "      <td>0.07400</td>\n",
       "      <td>...</td>\n",
       "      <td>22.88</td>\n",
       "      <td>27.66</td>\n",
       "      <td>153.20</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.3784</td>\n",
       "      <td>0.1932</td>\n",
       "      <td>0.3063</td>\n",
       "      <td>0.08368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>84458202</td>\n",
       "      <td>M</td>\n",
       "      <td>13.71</td>\n",
       "      <td>20.83</td>\n",
       "      <td>90.20</td>\n",
       "      <td>577.9</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.16450</td>\n",
       "      <td>0.09366</td>\n",
       "      <td>0.05985</td>\n",
       "      <td>...</td>\n",
       "      <td>17.06</td>\n",
       "      <td>28.14</td>\n",
       "      <td>110.60</td>\n",
       "      <td>897.0</td>\n",
       "      <td>0.1654</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>0.2678</td>\n",
       "      <td>0.1556</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.11510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>844981</td>\n",
       "      <td>M</td>\n",
       "      <td>13.00</td>\n",
       "      <td>21.82</td>\n",
       "      <td>87.50</td>\n",
       "      <td>519.8</td>\n",
       "      <td>0.12730</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.18590</td>\n",
       "      <td>0.09353</td>\n",
       "      <td>...</td>\n",
       "      <td>15.49</td>\n",
       "      <td>30.73</td>\n",
       "      <td>106.20</td>\n",
       "      <td>739.3</td>\n",
       "      <td>0.1703</td>\n",
       "      <td>0.5401</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.4378</td>\n",
       "      <td>0.10720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>84501001</td>\n",
       "      <td>M</td>\n",
       "      <td>12.46</td>\n",
       "      <td>24.04</td>\n",
       "      <td>83.97</td>\n",
       "      <td>475.9</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.23960</td>\n",
       "      <td>0.22730</td>\n",
       "      <td>0.08543</td>\n",
       "      <td>...</td>\n",
       "      <td>15.09</td>\n",
       "      <td>40.68</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.4</td>\n",
       "      <td>0.1853</td>\n",
       "      <td>1.0580</td>\n",
       "      <td>1.1050</td>\n",
       "      <td>0.2210</td>\n",
       "      <td>0.4366</td>\n",
       "      <td>0.20750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "5    843786         M        12.45         15.70           82.57      477.1   \n",
       "6    844359         M        18.25         19.98          119.60     1040.0   \n",
       "7  84458202         M        13.71         20.83           90.20      577.9   \n",
       "8    844981         M        13.00         21.82           87.50      519.8   \n",
       "9  84501001         M        12.46         24.04           83.97      475.9   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760         0.30010              0.14710   \n",
       "1          0.08474           0.07864         0.08690              0.07017   \n",
       "2          0.10960           0.15990         0.19740              0.12790   \n",
       "3          0.14250           0.28390         0.24140              0.10520   \n",
       "4          0.10030           0.13280         0.19800              0.10430   \n",
       "5          0.12780           0.17000         0.15780              0.08089   \n",
       "6          0.09463           0.10900         0.11270              0.07400   \n",
       "7          0.11890           0.16450         0.09366              0.05985   \n",
       "8          0.12730           0.19320         0.18590              0.09353   \n",
       "9          0.11860           0.23960         0.22730              0.08543   \n",
       "\n",
       "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0  ...         25.38          17.33           184.60      2019.0   \n",
       "1  ...         24.99          23.41           158.80      1956.0   \n",
       "2  ...         23.57          25.53           152.50      1709.0   \n",
       "3  ...         14.91          26.50            98.87       567.7   \n",
       "4  ...         22.54          16.67           152.20      1575.0   \n",
       "5  ...         15.47          23.75           103.40       741.6   \n",
       "6  ...         22.88          27.66           153.20      1606.0   \n",
       "7  ...         17.06          28.14           110.60       897.0   \n",
       "8  ...         15.49          30.73           106.20       739.3   \n",
       "9  ...         15.09          40.68            97.65       711.4   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "5            0.1791             0.5249           0.5355                0.1741   \n",
       "6            0.1442             0.2576           0.3784                0.1932   \n",
       "7            0.1654             0.3682           0.2678                0.1556   \n",
       "8            0.1703             0.5401           0.5390                0.2060   \n",
       "9            0.1853             1.0580           1.1050                0.2210   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  \n",
       "0          0.4601                  0.11890  \n",
       "1          0.2750                  0.08902  \n",
       "2          0.3613                  0.08758  \n",
       "3          0.6638                  0.17300  \n",
       "4          0.2364                  0.07678  \n",
       "5          0.3985                  0.12440  \n",
       "6          0.3063                  0.08368  \n",
       "7          0.3196                  0.11510  \n",
       "8          0.4378                  0.10720  \n",
       "9          0.4366                  0.20750  \n",
       "\n",
       "[10 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Looking at the sample data in the dataset\n",
    "\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f551737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Shape of the dataset\n",
    "\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27de79e5",
   "metadata": {},
   "source": [
    "The dataset consists of 32 columns and 569 rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e200754e",
   "metadata": {},
   "source": [
    "### 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531245bb",
   "metadata": {},
   "source": [
    "Data preprocessing is the process of getting our dataset ready for model training. In this section, we will perform the following preprocessing steps:\n",
    "\n",
    "1. Datatypes, Missing Data, and Summary Statistics\n",
    "2. Drop unnecessary columns\n",
    "3. Data Transformation\n",
    "4. Feature encoding "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643fe49d",
   "metadata": {},
   "source": [
    "#### 3.1 Datatypes, Missing Data, and Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "745acff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 32 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       569 non-null    int64  \n",
      " 1   diagnosis                569 non-null    object \n",
      " 2   radius_mean              569 non-null    float64\n",
      " 3   texture_mean             569 non-null    float64\n",
      " 4   perimeter_mean           569 non-null    float64\n",
      " 5   area_mean                569 non-null    float64\n",
      " 6   smoothness_mean          569 non-null    float64\n",
      " 7   compactness_mean         569 non-null    float64\n",
      " 8   concavity_mean           569 non-null    float64\n",
      " 9   concave points_mean      569 non-null    float64\n",
      " 10  symmetry_mean            569 non-null    float64\n",
      " 11  fractal_dimension_mean   569 non-null    float64\n",
      " 12  radius_se                569 non-null    float64\n",
      " 13  texture_se               569 non-null    float64\n",
      " 14  perimeter_se             569 non-null    float64\n",
      " 15  area_se                  569 non-null    float64\n",
      " 16  smoothness_se            569 non-null    float64\n",
      " 17  compactness_se           569 non-null    float64\n",
      " 18  concavity_se             569 non-null    float64\n",
      " 19  concave points_se        569 non-null    float64\n",
      " 20  symmetry_se              569 non-null    float64\n",
      " 21  fractal_dimension_se     569 non-null    float64\n",
      " 22  radius_worst             569 non-null    float64\n",
      " 23  texture_worst            569 non-null    float64\n",
      " 24  perimeter_worst          569 non-null    float64\n",
      " 25  area_worst               569 non-null    float64\n",
      " 26  smoothness_worst         569 non-null    float64\n",
      " 27  compactness_worst        569 non-null    float64\n",
      " 28  concavity_worst          569 non-null    float64\n",
      " 29  concave points_worst     569 non-null    float64\n",
      " 30  symmetry_worst           569 non-null    float64\n",
      " 31  fractal_dimension_worst  569 non-null    float64\n",
      "dtypes: float64(30), int64(1), object(1)\n",
      "memory usage: 142.4+ KB\n"
     ]
    }
   ],
   "source": [
    "### Looking at the datatypes of the dataset\n",
    "\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8851f9",
   "metadata": {},
   "source": [
    "Here, the column - diagnosis is categorical. Hence, we modify the datatype of these columns to category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7df279a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Changing the datatype of the column - dignosis in the dataset \n",
    "\n",
    "dataset.diagnosis = dataset.diagnosis.astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fcbbcf",
   "metadata": {},
   "source": [
    "Looking at the modified datatypes of the columns in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "887543e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 32 columns):\n",
      " #   Column                   Non-Null Count  Dtype   \n",
      "---  ------                   --------------  -----   \n",
      " 0   id                       569 non-null    int64   \n",
      " 1   diagnosis                569 non-null    category\n",
      " 2   radius_mean              569 non-null    float64 \n",
      " 3   texture_mean             569 non-null    float64 \n",
      " 4   perimeter_mean           569 non-null    float64 \n",
      " 5   area_mean                569 non-null    float64 \n",
      " 6   smoothness_mean          569 non-null    float64 \n",
      " 7   compactness_mean         569 non-null    float64 \n",
      " 8   concavity_mean           569 non-null    float64 \n",
      " 9   concave points_mean      569 non-null    float64 \n",
      " 10  symmetry_mean            569 non-null    float64 \n",
      " 11  fractal_dimension_mean   569 non-null    float64 \n",
      " 12  radius_se                569 non-null    float64 \n",
      " 13  texture_se               569 non-null    float64 \n",
      " 14  perimeter_se             569 non-null    float64 \n",
      " 15  area_se                  569 non-null    float64 \n",
      " 16  smoothness_se            569 non-null    float64 \n",
      " 17  compactness_se           569 non-null    float64 \n",
      " 18  concavity_se             569 non-null    float64 \n",
      " 19  concave points_se        569 non-null    float64 \n",
      " 20  symmetry_se              569 non-null    float64 \n",
      " 21  fractal_dimension_se     569 non-null    float64 \n",
      " 22  radius_worst             569 non-null    float64 \n",
      " 23  texture_worst            569 non-null    float64 \n",
      " 24  perimeter_worst          569 non-null    float64 \n",
      " 25  area_worst               569 non-null    float64 \n",
      " 26  smoothness_worst         569 non-null    float64 \n",
      " 27  compactness_worst        569 non-null    float64 \n",
      " 28  concavity_worst          569 non-null    float64 \n",
      " 29  concave points_worst     569 non-null    float64 \n",
      " 30  symmetry_worst           569 non-null    float64 \n",
      " 31  fractal_dimension_worst  569 non-null    float64 \n",
      "dtypes: category(1), float64(30), int64(1)\n",
      "memory usage: 138.6 KB\n"
     ]
    }
   ],
   "source": [
    "### Looking at the modified datatypes of the dataset\n",
    "\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2401c578",
   "metadata": {},
   "source": [
    "From the above data, we can see that the datatype of the column - diagnosis has changed from object to category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c019356e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                         0\n",
       "diagnosis                  0\n",
       "symmetry_worst             0\n",
       "concave points_worst       0\n",
       "concavity_worst            0\n",
       "compactness_worst          0\n",
       "smoothness_worst           0\n",
       "area_worst                 0\n",
       "perimeter_worst            0\n",
       "texture_worst              0\n",
       "radius_worst               0\n",
       "fractal_dimension_se       0\n",
       "symmetry_se                0\n",
       "concave points_se          0\n",
       "concavity_se               0\n",
       "compactness_se             0\n",
       "smoothness_se              0\n",
       "area_se                    0\n",
       "perimeter_se               0\n",
       "texture_se                 0\n",
       "radius_se                  0\n",
       "fractal_dimension_mean     0\n",
       "symmetry_mean              0\n",
       "concave points_mean        0\n",
       "concavity_mean             0\n",
       "compactness_mean           0\n",
       "smoothness_mean            0\n",
       "area_mean                  0\n",
       "perimeter_mean             0\n",
       "texture_mean               0\n",
       "radius_mean                0\n",
       "fractal_dimension_worst    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Missing data by columns in the dataset\n",
    "\n",
    "dataset.isnull().sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5f0056",
   "metadata": {},
   "source": [
    "From the above data, it is evident that there are no missing values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15aadccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Visual representation of the data in the dataset\n",
    "\n",
    "missingno.matrix(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61e6b144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.037183e+07</td>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>...</td>\n",
       "      <td>16.269190</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.250206e+08</td>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>...</td>\n",
       "      <td>4.833242</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.670000e+03</td>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.692180e+05</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>...</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.060240e+05</td>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>...</td>\n",
       "      <td>14.970000</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.813129e+06</td>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>...</td>\n",
       "      <td>18.790000</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.113205e+08</td>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>...</td>\n",
       "      <td>36.040000</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  radius_mean  texture_mean  perimeter_mean    area_mean  \\\n",
       "count  5.690000e+02   569.000000    569.000000      569.000000   569.000000   \n",
       "mean   3.037183e+07    14.127292     19.289649       91.969033   654.889104   \n",
       "std    1.250206e+08     3.524049      4.301036       24.298981   351.914129   \n",
       "min    8.670000e+03     6.981000      9.710000       43.790000   143.500000   \n",
       "25%    8.692180e+05    11.700000     16.170000       75.170000   420.300000   \n",
       "50%    9.060240e+05    13.370000     18.840000       86.240000   551.100000   \n",
       "75%    8.813129e+06    15.780000     21.800000      104.100000   782.700000   \n",
       "max    9.113205e+08    28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "count       569.000000        569.000000      569.000000           569.000000   \n",
       "mean          0.096360          0.104341        0.088799             0.048919   \n",
       "std           0.014064          0.052813        0.079720             0.038803   \n",
       "min           0.052630          0.019380        0.000000             0.000000   \n",
       "25%           0.086370          0.064920        0.029560             0.020310   \n",
       "50%           0.095870          0.092630        0.061540             0.033500   \n",
       "75%           0.105300          0.130400        0.130700             0.074000   \n",
       "max           0.163400          0.345400        0.426800             0.201200   \n",
       "\n",
       "       symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "count     569.000000  ...    569.000000     569.000000       569.000000   \n",
       "mean        0.181162  ...     16.269190      25.677223       107.261213   \n",
       "std         0.027414  ...      4.833242       6.146258        33.602542   \n",
       "min         0.106000  ...      7.930000      12.020000        50.410000   \n",
       "25%         0.161900  ...     13.010000      21.080000        84.110000   \n",
       "50%         0.179200  ...     14.970000      25.410000        97.660000   \n",
       "75%         0.195700  ...     18.790000      29.720000       125.400000   \n",
       "max         0.304000  ...     36.040000      49.540000       251.200000   \n",
       "\n",
       "        area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "count   569.000000        569.000000         569.000000       569.000000   \n",
       "mean    880.583128          0.132369           0.254265         0.272188   \n",
       "std     569.356993          0.022832           0.157336         0.208624   \n",
       "min     185.200000          0.071170           0.027290         0.000000   \n",
       "25%     515.300000          0.116600           0.147200         0.114500   \n",
       "50%     686.500000          0.131300           0.211900         0.226700   \n",
       "75%    1084.000000          0.146000           0.339100         0.382900   \n",
       "max    4254.000000          0.222600           1.058000         1.252000   \n",
       "\n",
       "       concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "count            569.000000      569.000000               569.000000  \n",
       "mean               0.114606        0.290076                 0.083946  \n",
       "std                0.065732        0.061867                 0.018061  \n",
       "min                0.000000        0.156500                 0.055040  \n",
       "25%                0.064930        0.250400                 0.071460  \n",
       "50%                0.099930        0.282200                 0.080040  \n",
       "75%                0.161400        0.317900                 0.092080  \n",
       "max                0.291000        0.663800                 0.207500  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Summary statistics of the numerical columns in the dataset\n",
    "\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d64733",
   "metadata": {},
   "source": [
    "#### 3.2 Drop unnecessary columns "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b79a1b",
   "metadata": {},
   "source": [
    "From the given dataset, we can see that the column id is a counter variable. Hence, we will drop the column - id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "402badde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>M</td>\n",
       "      <td>12.45</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.15780</td>\n",
       "      <td>0.08089</td>\n",
       "      <td>0.2087</td>\n",
       "      <td>...</td>\n",
       "      <td>15.47</td>\n",
       "      <td>23.75</td>\n",
       "      <td>103.40</td>\n",
       "      <td>741.6</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.5249</td>\n",
       "      <td>0.5355</td>\n",
       "      <td>0.1741</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.12440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>M</td>\n",
       "      <td>18.25</td>\n",
       "      <td>19.98</td>\n",
       "      <td>119.60</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>0.09463</td>\n",
       "      <td>0.10900</td>\n",
       "      <td>0.11270</td>\n",
       "      <td>0.07400</td>\n",
       "      <td>0.1794</td>\n",
       "      <td>...</td>\n",
       "      <td>22.88</td>\n",
       "      <td>27.66</td>\n",
       "      <td>153.20</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.3784</td>\n",
       "      <td>0.1932</td>\n",
       "      <td>0.3063</td>\n",
       "      <td>0.08368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>M</td>\n",
       "      <td>13.71</td>\n",
       "      <td>20.83</td>\n",
       "      <td>90.20</td>\n",
       "      <td>577.9</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.16450</td>\n",
       "      <td>0.09366</td>\n",
       "      <td>0.05985</td>\n",
       "      <td>0.2196</td>\n",
       "      <td>...</td>\n",
       "      <td>17.06</td>\n",
       "      <td>28.14</td>\n",
       "      <td>110.60</td>\n",
       "      <td>897.0</td>\n",
       "      <td>0.1654</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>0.2678</td>\n",
       "      <td>0.1556</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.11510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>M</td>\n",
       "      <td>13.00</td>\n",
       "      <td>21.82</td>\n",
       "      <td>87.50</td>\n",
       "      <td>519.8</td>\n",
       "      <td>0.12730</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.18590</td>\n",
       "      <td>0.09353</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>...</td>\n",
       "      <td>15.49</td>\n",
       "      <td>30.73</td>\n",
       "      <td>106.20</td>\n",
       "      <td>739.3</td>\n",
       "      <td>0.1703</td>\n",
       "      <td>0.5401</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.4378</td>\n",
       "      <td>0.10720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>M</td>\n",
       "      <td>12.46</td>\n",
       "      <td>24.04</td>\n",
       "      <td>83.97</td>\n",
       "      <td>475.9</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.23960</td>\n",
       "      <td>0.22730</td>\n",
       "      <td>0.08543</td>\n",
       "      <td>0.2030</td>\n",
       "      <td>...</td>\n",
       "      <td>15.09</td>\n",
       "      <td>40.68</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.4</td>\n",
       "      <td>0.1853</td>\n",
       "      <td>1.0580</td>\n",
       "      <td>1.1050</td>\n",
       "      <td>0.2210</td>\n",
       "      <td>0.4366</td>\n",
       "      <td>0.20750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0         M        17.99         10.38          122.80     1001.0   \n",
       "1         M        20.57         17.77          132.90     1326.0   \n",
       "2         M        19.69         21.25          130.00     1203.0   \n",
       "3         M        11.42         20.38           77.58      386.1   \n",
       "4         M        20.29         14.34          135.10     1297.0   \n",
       "5         M        12.45         15.70           82.57      477.1   \n",
       "6         M        18.25         19.98          119.60     1040.0   \n",
       "7         M        13.71         20.83           90.20      577.9   \n",
       "8         M        13.00         21.82           87.50      519.8   \n",
       "9         M        12.46         24.04           83.97      475.9   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760         0.30010              0.14710   \n",
       "1          0.08474           0.07864         0.08690              0.07017   \n",
       "2          0.10960           0.15990         0.19740              0.12790   \n",
       "3          0.14250           0.28390         0.24140              0.10520   \n",
       "4          0.10030           0.13280         0.19800              0.10430   \n",
       "5          0.12780           0.17000         0.15780              0.08089   \n",
       "6          0.09463           0.10900         0.11270              0.07400   \n",
       "7          0.11890           0.16450         0.09366              0.05985   \n",
       "8          0.12730           0.19320         0.18590              0.09353   \n",
       "9          0.11860           0.23960         0.22730              0.08543   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "5         0.2087  ...         15.47          23.75           103.40   \n",
       "6         0.1794  ...         22.88          27.66           153.20   \n",
       "7         0.2196  ...         17.06          28.14           110.60   \n",
       "8         0.2350  ...         15.49          30.73           106.20   \n",
       "9         0.2030  ...         15.09          40.68            97.65   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "5       741.6            0.1791             0.5249           0.5355   \n",
       "6      1606.0            0.1442             0.2576           0.3784   \n",
       "7       897.0            0.1654             0.3682           0.2678   \n",
       "8       739.3            0.1703             0.5401           0.5390   \n",
       "9       711.4            0.1853             1.0580           1.1050   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "5                0.1741          0.3985                  0.12440  \n",
       "6                0.1932          0.3063                  0.08368  \n",
       "7                0.1556          0.3196                  0.11510  \n",
       "8                0.2060          0.4378                  0.10720  \n",
       "9                0.2210          0.4366                  0.20750  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Drop the column - id\n",
    "\n",
    "dataset.drop(['id'], axis = 1, inplace = True)\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6186706c",
   "metadata": {},
   "source": [
    "#### 3.3 Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e32fe9",
   "metadata": {},
   "source": [
    "In this section, we will transform the data using min max scaling. Min-Max scaling also known as min-max scaling or min-max normalization, rescaling is the simplest method and consists in rescaling the range of features to scale the range in [0, 1] or [−1, 1]. Selecting the target range depends on the nature of the data.\n",
    "\n",
    "Here, we will scale the data to a range of [0, 1]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c0a8ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### A function to perform min-max scaling\n",
    "\n",
    "def min_max_scaling(dataset, column):\n",
    "    data = list(dataset[column])\n",
    "    new_data = [(value - min(data))/(max(data) - min(data)) for value in data]\n",
    "    dataset[column] = new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0021361c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>0.521037</td>\n",
       "      <td>0.022658</td>\n",
       "      <td>0.545989</td>\n",
       "      <td>0.363733</td>\n",
       "      <td>0.593753</td>\n",
       "      <td>0.792037</td>\n",
       "      <td>0.703140</td>\n",
       "      <td>0.731113</td>\n",
       "      <td>0.686364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.620776</td>\n",
       "      <td>0.141525</td>\n",
       "      <td>0.668310</td>\n",
       "      <td>0.450698</td>\n",
       "      <td>0.601136</td>\n",
       "      <td>0.619292</td>\n",
       "      <td>0.568610</td>\n",
       "      <td>0.912027</td>\n",
       "      <td>0.598462</td>\n",
       "      <td>0.418864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>0.643144</td>\n",
       "      <td>0.272574</td>\n",
       "      <td>0.615783</td>\n",
       "      <td>0.501591</td>\n",
       "      <td>0.289880</td>\n",
       "      <td>0.181768</td>\n",
       "      <td>0.203608</td>\n",
       "      <td>0.348757</td>\n",
       "      <td>0.379798</td>\n",
       "      <td>...</td>\n",
       "      <td>0.606901</td>\n",
       "      <td>0.303571</td>\n",
       "      <td>0.539818</td>\n",
       "      <td>0.435214</td>\n",
       "      <td>0.347553</td>\n",
       "      <td>0.154563</td>\n",
       "      <td>0.192971</td>\n",
       "      <td>0.639175</td>\n",
       "      <td>0.233590</td>\n",
       "      <td>0.222878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>0.601496</td>\n",
       "      <td>0.390260</td>\n",
       "      <td>0.595743</td>\n",
       "      <td>0.449417</td>\n",
       "      <td>0.514309</td>\n",
       "      <td>0.431017</td>\n",
       "      <td>0.462512</td>\n",
       "      <td>0.635686</td>\n",
       "      <td>0.509596</td>\n",
       "      <td>...</td>\n",
       "      <td>0.556386</td>\n",
       "      <td>0.360075</td>\n",
       "      <td>0.508442</td>\n",
       "      <td>0.374508</td>\n",
       "      <td>0.483590</td>\n",
       "      <td>0.385375</td>\n",
       "      <td>0.359744</td>\n",
       "      <td>0.835052</td>\n",
       "      <td>0.403706</td>\n",
       "      <td>0.213433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>0.210090</td>\n",
       "      <td>0.360839</td>\n",
       "      <td>0.233501</td>\n",
       "      <td>0.102906</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.811361</td>\n",
       "      <td>0.565604</td>\n",
       "      <td>0.522863</td>\n",
       "      <td>0.776263</td>\n",
       "      <td>...</td>\n",
       "      <td>0.248310</td>\n",
       "      <td>0.385928</td>\n",
       "      <td>0.241347</td>\n",
       "      <td>0.094008</td>\n",
       "      <td>0.915472</td>\n",
       "      <td>0.814012</td>\n",
       "      <td>0.548642</td>\n",
       "      <td>0.884880</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.773711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>0.629893</td>\n",
       "      <td>0.156578</td>\n",
       "      <td>0.630986</td>\n",
       "      <td>0.489290</td>\n",
       "      <td>0.430351</td>\n",
       "      <td>0.347893</td>\n",
       "      <td>0.463918</td>\n",
       "      <td>0.518390</td>\n",
       "      <td>0.378283</td>\n",
       "      <td>...</td>\n",
       "      <td>0.519744</td>\n",
       "      <td>0.123934</td>\n",
       "      <td>0.506948</td>\n",
       "      <td>0.341575</td>\n",
       "      <td>0.437364</td>\n",
       "      <td>0.172415</td>\n",
       "      <td>0.319489</td>\n",
       "      <td>0.558419</td>\n",
       "      <td>0.157500</td>\n",
       "      <td>0.142595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>M</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.428813</td>\n",
       "      <td>0.678668</td>\n",
       "      <td>0.566490</td>\n",
       "      <td>0.526948</td>\n",
       "      <td>0.296055</td>\n",
       "      <td>0.571462</td>\n",
       "      <td>0.690358</td>\n",
       "      <td>0.336364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.623266</td>\n",
       "      <td>0.383262</td>\n",
       "      <td>0.576174</td>\n",
       "      <td>0.452664</td>\n",
       "      <td>0.461137</td>\n",
       "      <td>0.178527</td>\n",
       "      <td>0.328035</td>\n",
       "      <td>0.761512</td>\n",
       "      <td>0.097575</td>\n",
       "      <td>0.105667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>M</td>\n",
       "      <td>0.622320</td>\n",
       "      <td>0.626987</td>\n",
       "      <td>0.604036</td>\n",
       "      <td>0.474019</td>\n",
       "      <td>0.407782</td>\n",
       "      <td>0.257714</td>\n",
       "      <td>0.337395</td>\n",
       "      <td>0.486630</td>\n",
       "      <td>0.349495</td>\n",
       "      <td>...</td>\n",
       "      <td>0.560655</td>\n",
       "      <td>0.699094</td>\n",
       "      <td>0.520892</td>\n",
       "      <td>0.379915</td>\n",
       "      <td>0.300007</td>\n",
       "      <td>0.159997</td>\n",
       "      <td>0.256789</td>\n",
       "      <td>0.559450</td>\n",
       "      <td>0.198502</td>\n",
       "      <td>0.074315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>M</td>\n",
       "      <td>0.455251</td>\n",
       "      <td>0.621238</td>\n",
       "      <td>0.445788</td>\n",
       "      <td>0.303118</td>\n",
       "      <td>0.288165</td>\n",
       "      <td>0.254340</td>\n",
       "      <td>0.216753</td>\n",
       "      <td>0.263519</td>\n",
       "      <td>0.267677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.393099</td>\n",
       "      <td>0.589019</td>\n",
       "      <td>0.379949</td>\n",
       "      <td>0.230731</td>\n",
       "      <td>0.282177</td>\n",
       "      <td>0.273705</td>\n",
       "      <td>0.271805</td>\n",
       "      <td>0.487285</td>\n",
       "      <td>0.128721</td>\n",
       "      <td>0.151909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>M</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.663510</td>\n",
       "      <td>0.665538</td>\n",
       "      <td>0.475716</td>\n",
       "      <td>0.588336</td>\n",
       "      <td>0.790197</td>\n",
       "      <td>0.823336</td>\n",
       "      <td>0.755467</td>\n",
       "      <td>0.675253</td>\n",
       "      <td>...</td>\n",
       "      <td>0.633582</td>\n",
       "      <td>0.730277</td>\n",
       "      <td>0.668310</td>\n",
       "      <td>0.402035</td>\n",
       "      <td>0.619626</td>\n",
       "      <td>0.815758</td>\n",
       "      <td>0.749760</td>\n",
       "      <td>0.910653</td>\n",
       "      <td>0.497142</td>\n",
       "      <td>0.452315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>B</td>\n",
       "      <td>0.036869</td>\n",
       "      <td>0.501522</td>\n",
       "      <td>0.028540</td>\n",
       "      <td>0.015907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266162</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054287</td>\n",
       "      <td>0.489072</td>\n",
       "      <td>0.043578</td>\n",
       "      <td>0.020497</td>\n",
       "      <td>0.124084</td>\n",
       "      <td>0.036043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.257441</td>\n",
       "      <td>0.100682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0           M     0.521037      0.022658        0.545989   0.363733   \n",
       "1           M     0.643144      0.272574        0.615783   0.501591   \n",
       "2           M     0.601496      0.390260        0.595743   0.449417   \n",
       "3           M     0.210090      0.360839        0.233501   0.102906   \n",
       "4           M     0.629893      0.156578        0.630986   0.489290   \n",
       "..        ...          ...           ...             ...        ...   \n",
       "564         M     0.690000      0.428813        0.678668   0.566490   \n",
       "565         M     0.622320      0.626987        0.604036   0.474019   \n",
       "566         M     0.455251      0.621238        0.445788   0.303118   \n",
       "567         M     0.644564      0.663510        0.665538   0.475716   \n",
       "568         B     0.036869      0.501522        0.028540   0.015907   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0           0.593753          0.792037        0.703140             0.731113   \n",
       "1           0.289880          0.181768        0.203608             0.348757   \n",
       "2           0.514309          0.431017        0.462512             0.635686   \n",
       "3           0.811321          0.811361        0.565604             0.522863   \n",
       "4           0.430351          0.347893        0.463918             0.518390   \n",
       "..               ...               ...             ...                  ...   \n",
       "564         0.526948          0.296055        0.571462             0.690358   \n",
       "565         0.407782          0.257714        0.337395             0.486630   \n",
       "566         0.288165          0.254340        0.216753             0.263519   \n",
       "567         0.588336          0.790197        0.823336             0.755467   \n",
       "568         0.000000          0.074351        0.000000             0.000000   \n",
       "\n",
       "     symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.686364  ...      0.620776       0.141525         0.668310   \n",
       "1         0.379798  ...      0.606901       0.303571         0.539818   \n",
       "2         0.509596  ...      0.556386       0.360075         0.508442   \n",
       "3         0.776263  ...      0.248310       0.385928         0.241347   \n",
       "4         0.378283  ...      0.519744       0.123934         0.506948   \n",
       "..             ...  ...           ...            ...              ...   \n",
       "564       0.336364  ...      0.623266       0.383262         0.576174   \n",
       "565       0.349495  ...      0.560655       0.699094         0.520892   \n",
       "566       0.267677  ...      0.393099       0.589019         0.379949   \n",
       "567       0.675253  ...      0.633582       0.730277         0.668310   \n",
       "568       0.266162  ...      0.054287       0.489072         0.043578   \n",
       "\n",
       "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      0.450698          0.601136           0.619292         0.568610   \n",
       "1      0.435214          0.347553           0.154563         0.192971   \n",
       "2      0.374508          0.483590           0.385375         0.359744   \n",
       "3      0.094008          0.915472           0.814012         0.548642   \n",
       "4      0.341575          0.437364           0.172415         0.319489   \n",
       "..          ...               ...                ...              ...   \n",
       "564    0.452664          0.461137           0.178527         0.328035   \n",
       "565    0.379915          0.300007           0.159997         0.256789   \n",
       "566    0.230731          0.282177           0.273705         0.271805   \n",
       "567    0.402035          0.619626           0.815758         0.749760   \n",
       "568    0.020497          0.124084           0.036043         0.000000   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.912027        0.598462                 0.418864  \n",
       "1                0.639175        0.233590                 0.222878  \n",
       "2                0.835052        0.403706                 0.213433  \n",
       "3                0.884880        1.000000                 0.773711  \n",
       "4                0.558419        0.157500                 0.142595  \n",
       "..                    ...             ...                      ...  \n",
       "564              0.761512        0.097575                 0.105667  \n",
       "565              0.559450        0.198502                 0.074315  \n",
       "566              0.487285        0.128721                 0.151909  \n",
       "567              0.910653        0.497142                 0.452315  \n",
       "568              0.000000        0.257441                 0.100682  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Scaling all the numerical columns \n",
    "\n",
    "columns = list(dataset.columns)\n",
    "numerical_columns = columns[1 : ]\n",
    "\n",
    "for each_column in numerical_columns:\n",
    "    min_max_scaling(dataset, each_column)\n",
    "    \n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caad658b",
   "metadata": {},
   "source": [
    "#### 3.4 Feature Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f82b5c1",
   "metadata": {},
   "source": [
    "In the dataset, we have one categorical column - diagnosis (target variable). Here, the value 'M' means malignant and 'B' means benign. A benign tumor has distinct, smooth, regular borders. A malignant tumor has irregular borders and grows faster than a benign tumor. A malignant tumor can also spread to other parts of your body. A benign tumor can become quite large, but it will not invade nearby tissue or spread to other parts of your body.\n",
    "\n",
    "Here, we will use 0-1 encoding such that M means 1 and B means 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc157bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Encoding the target column - diagnosis\n",
    "\n",
    "target_column = dataset['diagnosis']\n",
    "encoded_target = [0 if value == 'B' else 1 for value in target_column]\n",
    "encoded_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9537dca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.521037</td>\n",
       "      <td>0.022658</td>\n",
       "      <td>0.545989</td>\n",
       "      <td>0.363733</td>\n",
       "      <td>0.593753</td>\n",
       "      <td>0.792037</td>\n",
       "      <td>0.703140</td>\n",
       "      <td>0.731113</td>\n",
       "      <td>0.686364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.620776</td>\n",
       "      <td>0.141525</td>\n",
       "      <td>0.668310</td>\n",
       "      <td>0.450698</td>\n",
       "      <td>0.601136</td>\n",
       "      <td>0.619292</td>\n",
       "      <td>0.568610</td>\n",
       "      <td>0.912027</td>\n",
       "      <td>0.598462</td>\n",
       "      <td>0.418864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.643144</td>\n",
       "      <td>0.272574</td>\n",
       "      <td>0.615783</td>\n",
       "      <td>0.501591</td>\n",
       "      <td>0.289880</td>\n",
       "      <td>0.181768</td>\n",
       "      <td>0.203608</td>\n",
       "      <td>0.348757</td>\n",
       "      <td>0.379798</td>\n",
       "      <td>...</td>\n",
       "      <td>0.606901</td>\n",
       "      <td>0.303571</td>\n",
       "      <td>0.539818</td>\n",
       "      <td>0.435214</td>\n",
       "      <td>0.347553</td>\n",
       "      <td>0.154563</td>\n",
       "      <td>0.192971</td>\n",
       "      <td>0.639175</td>\n",
       "      <td>0.233590</td>\n",
       "      <td>0.222878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.601496</td>\n",
       "      <td>0.390260</td>\n",
       "      <td>0.595743</td>\n",
       "      <td>0.449417</td>\n",
       "      <td>0.514309</td>\n",
       "      <td>0.431017</td>\n",
       "      <td>0.462512</td>\n",
       "      <td>0.635686</td>\n",
       "      <td>0.509596</td>\n",
       "      <td>...</td>\n",
       "      <td>0.556386</td>\n",
       "      <td>0.360075</td>\n",
       "      <td>0.508442</td>\n",
       "      <td>0.374508</td>\n",
       "      <td>0.483590</td>\n",
       "      <td>0.385375</td>\n",
       "      <td>0.359744</td>\n",
       "      <td>0.835052</td>\n",
       "      <td>0.403706</td>\n",
       "      <td>0.213433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.210090</td>\n",
       "      <td>0.360839</td>\n",
       "      <td>0.233501</td>\n",
       "      <td>0.102906</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.811361</td>\n",
       "      <td>0.565604</td>\n",
       "      <td>0.522863</td>\n",
       "      <td>0.776263</td>\n",
       "      <td>...</td>\n",
       "      <td>0.248310</td>\n",
       "      <td>0.385928</td>\n",
       "      <td>0.241347</td>\n",
       "      <td>0.094008</td>\n",
       "      <td>0.915472</td>\n",
       "      <td>0.814012</td>\n",
       "      <td>0.548642</td>\n",
       "      <td>0.884880</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.773711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.629893</td>\n",
       "      <td>0.156578</td>\n",
       "      <td>0.630986</td>\n",
       "      <td>0.489290</td>\n",
       "      <td>0.430351</td>\n",
       "      <td>0.347893</td>\n",
       "      <td>0.463918</td>\n",
       "      <td>0.518390</td>\n",
       "      <td>0.378283</td>\n",
       "      <td>...</td>\n",
       "      <td>0.519744</td>\n",
       "      <td>0.123934</td>\n",
       "      <td>0.506948</td>\n",
       "      <td>0.341575</td>\n",
       "      <td>0.437364</td>\n",
       "      <td>0.172415</td>\n",
       "      <td>0.319489</td>\n",
       "      <td>0.558419</td>\n",
       "      <td>0.157500</td>\n",
       "      <td>0.142595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0          1     0.521037      0.022658        0.545989   0.363733   \n",
       "1          1     0.643144      0.272574        0.615783   0.501591   \n",
       "2          1     0.601496      0.390260        0.595743   0.449417   \n",
       "3          1     0.210090      0.360839        0.233501   0.102906   \n",
       "4          1     0.629893      0.156578        0.630986   0.489290   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0         0.593753          0.792037        0.703140             0.731113   \n",
       "1         0.289880          0.181768        0.203608             0.348757   \n",
       "2         0.514309          0.431017        0.462512             0.635686   \n",
       "3         0.811321          0.811361        0.565604             0.522863   \n",
       "4         0.430351          0.347893        0.463918             0.518390   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0       0.686364  ...      0.620776       0.141525         0.668310   \n",
       "1       0.379798  ...      0.606901       0.303571         0.539818   \n",
       "2       0.509596  ...      0.556386       0.360075         0.508442   \n",
       "3       0.776263  ...      0.248310       0.385928         0.241347   \n",
       "4       0.378283  ...      0.519744       0.123934         0.506948   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0    0.450698          0.601136           0.619292         0.568610   \n",
       "1    0.435214          0.347553           0.154563         0.192971   \n",
       "2    0.374508          0.483590           0.385375         0.359744   \n",
       "3    0.094008          0.915472           0.814012         0.548642   \n",
       "4    0.341575          0.437364           0.172415         0.319489   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0              0.912027        0.598462                 0.418864  \n",
       "1              0.639175        0.233590                 0.222878  \n",
       "2              0.835052        0.403706                 0.213433  \n",
       "3              0.884880        1.000000                 0.773711  \n",
       "4              0.558419        0.157500                 0.142595  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Modifying the target column of the dataset\n",
    "\n",
    "dataset['diagnosis'] = encoded_target\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b942e9b9",
   "metadata": {},
   "source": [
    "### 4. Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1812541a",
   "metadata": {},
   "source": [
    "Scikit-learn is one of the most popular libraries for machine learning in Python and that is what we will use in the modelling part of this project.\n",
    "\n",
    "Since Breast Cancer Detection is a classfication problem, we will need to use classfication models, also known as classifiers, to train on our model to make predictions. I highly recommend checking out the scikit-learn documentation for more information on the different machine learning models available in their library. I have chosen the following classifiers for the job:\n",
    "\n",
    "Logistic regression\n",
    "Support vector classification\n",
    "K-nearest neighbours\n",
    "Naive Bayes\n",
    "Decision tree\n",
    "Random forest\n",
    "\n",
    "In this section of the notebook, I will fit the models to the training set as outlined above and evaluate their accuracy at making predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115aa043",
   "metadata": {},
   "source": [
    "#### 4.1 Splitting the data into Training and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8bd791fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Splitting the data into independent and dependent matrices - X and Y\n",
    "\n",
    "X = dataset.iloc[:, 1:].values\n",
    "Y = dataset.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1cd257b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.52103744, 0.0226581 , 0.54598853, ..., 0.91202749, 0.59846245,\n",
       "        0.41886396],\n",
       "       [0.64314449, 0.27257355, 0.61578329, ..., 0.63917526, 0.23358959,\n",
       "        0.22287813],\n",
       "       [0.60149557, 0.3902604 , 0.59574321, ..., 0.83505155, 0.40370589,\n",
       "        0.21343303],\n",
       "       ...,\n",
       "       [0.45525108, 0.62123774, 0.44578813, ..., 0.48728522, 0.12872068,\n",
       "        0.1519087 ],\n",
       "       [0.64456434, 0.66351031, 0.66553797, ..., 0.91065292, 0.49714173,\n",
       "        0.45231536],\n",
       "       [0.03686876, 0.50152181, 0.02853984, ..., 0.        , 0.25744136,\n",
       "        0.10068215]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Looking at the independent matrix X\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "465a51e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Looking at the dependent matrix Y\n",
    "\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fcdd3d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dividing the data into training and test sets in the ratio of 80:20\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, shuffle = True, random_state = 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b87fc0c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9578778 , 0.4112276 , 0.95577362, ..., 0.92371134, 0.25448453,\n",
       "        0.16909353],\n",
       "       [0.6682285 , 0.36557322, 0.65171723, ..., 0.78350515, 0.13857678,\n",
       "        0.12600026],\n",
       "       [0.41975484, 0.48156916, 0.41400041, ..., 0.38453608, 0.24521979,\n",
       "        0.05135773],\n",
       "       ...,\n",
       "       [0.23044157, 0.26208996, 0.21940433, ..., 0.31408935, 0.30277942,\n",
       "        0.09858323],\n",
       "       [0.29480808, 0.62056138, 0.2839472 , ..., 0.27347079, 0.17898679,\n",
       "        0.06158993],\n",
       "       [0.31042643, 0.15725397, 0.30177597, ..., 0.44261168, 0.27833629,\n",
       "        0.11511216]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "69d3cf02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.27398362, 0.39567129, 0.26418354, ..., 0.16402062, 0.12103292,\n",
       "        0.08966286],\n",
       "       [0.20961711, 0.03753805, 0.20420151, ..., 0.30783505, 0.28602405,\n",
       "        0.19801915],\n",
       "       [0.64219793, 0.37707136, 0.64964412, ..., 0.73814433, 0.29804849,\n",
       "        0.13544536],\n",
       "       ...,\n",
       "       [0.16986133, 0.29117349, 0.15914588, ..., 0.07635739, 0.22353637,\n",
       "        0.08080808],\n",
       "       [0.1930522 , 0.25059182, 0.18975883, ..., 0.32694158, 0.23950325,\n",
       "        0.40508986],\n",
       "       [0.13128875, 0.62529591, 0.12362656, ..., 0.16721649, 0.14902425,\n",
       "        0.11196379]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98edee4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
       "       1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c95a53d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1,\n",
       "       0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b931ece",
   "metadata": {},
   "source": [
    "#### 4.2 Fit Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc431b6",
   "metadata": {},
   "source": [
    "In this section, we use various machine learning models to predict the results for our sample test data (X_test). Based on the performance of each model, we select one best model based on the model's accuracy. We will store the model and its accuracy so that we can tabulate them later for choosing the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "80b8479a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dictionary to store model and its accuracy\n",
    "\n",
    "model_performance = OrderedDict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24a4a85",
   "metadata": {},
   "source": [
    "##### 4.2.1 Applying Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d2c1fff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=27)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Training the Logistic Regression model on the dataset\n",
    "\n",
    "logistic_classifier = LogisticRegression(random_state = 27)\n",
    "logistic_classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b23af7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "### Predicting the Test set results\n",
    "\n",
    "Y_pred = logistic_classifier.predict(X_test)\n",
    "print(np.concatenate((Y_pred.reshape(len(Y_pred), 1), Y_test.reshape(len(Y_test), 1)), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d33de9c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[69  0]\n",
      " [ 3 42]]\n",
      "The accuracy of this model is 97.37 %.\n"
     ]
    }
   ],
   "source": [
    "### Making the confusion matrix\n",
    "\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)\n",
    "\n",
    "### Printing the accuracy of the model\n",
    "\n",
    "logistic_accuracy = round(100 * accuracy_score(Y_test, Y_pred), 2)\n",
    "model_performance['Logistic Regression'] = logistic_accuracy\n",
    "\n",
    "print('The accuracy of this model is {} %.'.format(logistic_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b1d06d",
   "metadata": {},
   "source": [
    "##### 4.2.2 Applying Support Vector Classification - Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa1e50b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear', random_state=27)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Applying Linear SVM Classification model\n",
    "\n",
    "linear_svm_classifier = SVC(kernel = 'linear', random_state = 27)\n",
    "linear_svm_classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f395fa6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "### Predicting the Test set results\n",
    "\n",
    "Y_pred = linear_svm_classifier.predict(X_test)\n",
    "print(np.concatenate((Y_pred.reshape(len(Y_pred), 1), Y_test.reshape(len(Y_test), 1)), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "94244e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[69  0]\n",
      " [ 3 42]]\n",
      "The accuracy of this model is 97.37 %.\n"
     ]
    }
   ],
   "source": [
    "### Making the confusion matrix\n",
    "\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)\n",
    "\n",
    "### Printing the accuracy of the model\n",
    "\n",
    "linear_svc_accuracy = round(100 * accuracy_score(Y_test, Y_pred), 2)\n",
    "model_performance['Linear SVC'] = linear_svc_accuracy\n",
    "print('The accuracy of this model is {} %.'.format(linear_svc_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbe3fe4",
   "metadata": {},
   "source": [
    "##### 4.2.3 Applying Support Vector Classification - Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ffdc8dbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(random_state=27)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Applying Kernel SVM Classification model\n",
    "\n",
    "kernel_svm_classifier = SVC(kernel = 'rbf', random_state = 27)\n",
    "kernel_svm_classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "932df305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "### Predicting the Test set results\n",
    "\n",
    "Y_pred = kernel_svm_classifier.predict(X_test)\n",
    "print(np.concatenate((Y_pred.reshape(len(Y_pred), 1), Y_test.reshape(len(Y_test), 1)), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d049d9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[69  0]\n",
      " [ 2 43]]\n",
      "The accuracy of this model is 98.25 %.\n"
     ]
    }
   ],
   "source": [
    "### Making the confusion matrix\n",
    "\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)\n",
    "\n",
    "### Printing the accuracy of the model\n",
    "\n",
    "kernel_svc_accuracy = round(100 * accuracy_score(Y_test, Y_pred), 2)\n",
    "model_performance['Kernel SVC'] = kernel_svc_accuracy\n",
    "print('The accuracy of this model is {} %.'.format(kernel_svc_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730e515a",
   "metadata": {},
   "source": [
    "##### 4.2.4 Applying K-Nearest Neighbors (1-NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c5f12d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Applying 1NN model\n",
    "\n",
    "classifier_1nn = KNeighborsClassifier(n_neighbors = 1, algorithm = 'auto', p = 2, metric = 'minkowski')\n",
    "classifier_1nn.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "44a62426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "### Predicting the Test set results\n",
    "\n",
    "Y_pred = classifier_1nn.predict(X_test)\n",
    "print(np.concatenate((Y_pred.reshape(len(Y_pred), 1), Y_test.reshape(len(Y_test), 1)), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "68ce447d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[66  3]\n",
      " [ 3 42]]\n",
      "The accuracy of this model is 94.74 %.\n"
     ]
    }
   ],
   "source": [
    "### Making the confusion matrix\n",
    "\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)\n",
    "\n",
    "### Printing the accuracy of the model\n",
    "\n",
    "nn1_accuracy = round(100 * accuracy_score(Y_test, Y_pred), 2)\n",
    "model_performance['1 Nearest Neighbors'] = nn1_accuracy\n",
    "print('The accuracy of this model is {} %.'.format(nn1_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4370573",
   "metadata": {},
   "source": [
    "##### 4.2.5 Applying K-Nearest Neighbors (3-NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "86916f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Applying 3NN model\n",
    "\n",
    "classifier_3nn = KNeighborsClassifier(n_neighbors = 3, algorithm = 'auto', p = 2, metric = 'minkowski')\n",
    "classifier_3nn.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2fb3a3b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "### Predicting the Test set results\n",
    "\n",
    "Y_pred = classifier_3nn.predict(X_test)\n",
    "print(np.concatenate((Y_pred.reshape(len(Y_pred), 1), Y_test.reshape(len(Y_test), 1)), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ed425bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[68  1]\n",
      " [ 2 43]]\n",
      "The accuracy of this model is 97.37 %.\n"
     ]
    }
   ],
   "source": [
    "### Making the confusion matrix\n",
    "\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)\n",
    "\n",
    "### Printing the accuracy of the model\n",
    "\n",
    "nn3_accuracy = round(100 * accuracy_score(Y_test, Y_pred), 2)\n",
    "model_performance['3 Nearest Neighbors'] = nn3_accuracy\n",
    "print('The accuracy of this model is {} %.'.format(nn3_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376e71b9",
   "metadata": {},
   "source": [
    "##### 4.2.6 Applying K-Nearest Neighbors (5-NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a1e81d16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Applying 5NN model\n",
    "\n",
    "classifier_5nn = KNeighborsClassifier(n_neighbors = 5, algorithm = 'auto', p = 2, metric = 'minkowski')\n",
    "classifier_5nn.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a10cfb01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "### Predicting the Test set results\n",
    "\n",
    "Y_pred = classifier_5nn.predict(X_test)\n",
    "print(np.concatenate((Y_pred.reshape(len(Y_pred), 1), Y_test.reshape(len(Y_test), 1)), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c432f602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[68  1]\n",
      " [ 2 43]]\n",
      "The accuracy of this model is 97.37 %.\n"
     ]
    }
   ],
   "source": [
    "### Making the confusion matrix\n",
    "\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)\n",
    "\n",
    "### Printing the accuracy of the model\n",
    "\n",
    "nn5_accuracy = round(100 * accuracy_score(Y_test, Y_pred), 2)\n",
    "model_performance['5 Nearest Neighbors'] = nn5_accuracy\n",
    "print('The accuracy of this model is {} %.'.format(nn5_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dc880b",
   "metadata": {},
   "source": [
    "##### 4.2.7 Applying K-Nearest Neighbors (7-NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c2a44cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=7)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Applying 7NN model\n",
    "\n",
    "classifier_7nn = KNeighborsClassifier(n_neighbors = 7, algorithm = 'auto', p = 2, metric = 'minkowski')\n",
    "classifier_7nn.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4e989f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "### Predicting the Test set results\n",
    "\n",
    "Y_pred = classifier_7nn.predict(X_test)\n",
    "print(np.concatenate((Y_pred.reshape(len(Y_pred), 1), Y_test.reshape(len(Y_test), 1)), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c0ec11b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[68  1]\n",
      " [ 2 43]]\n",
      "The accuracy of this model is 97.37 %.\n"
     ]
    }
   ],
   "source": [
    "### Making the confusion matrix\n",
    "\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)\n",
    "\n",
    "### Printing the accuracy of the model\n",
    "\n",
    "nn7_accuracy = round(100 * accuracy_score(Y_test, Y_pred), 2)\n",
    "model_performance['7 Nearest Neighbors'] = nn7_accuracy\n",
    "print('The accuracy of this model is {} %.'.format(nn7_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad94468",
   "metadata": {},
   "source": [
    "##### 4.2.8 Applying K-Nearest Neighbors (9-NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "796d9800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=9)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Applying 9NN model\n",
    "\n",
    "classifier_9nn = KNeighborsClassifier(n_neighbors = 9, algorithm = 'auto', p = 2, metric = 'minkowski')\n",
    "classifier_9nn.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d24c3ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "### Predicting the Test set results\n",
    "\n",
    "Y_pred = classifier_9nn.predict(X_test)\n",
    "print(np.concatenate((Y_pred.reshape(len(Y_pred), 1), Y_test.reshape(len(Y_test), 1)), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ad056935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[68  1]\n",
      " [ 4 41]]\n",
      "The accuracy of this model is 95.61 %.\n"
     ]
    }
   ],
   "source": [
    "### Making the confusion matrix\n",
    "\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)\n",
    "\n",
    "### Printing the accuracy of the model\n",
    "\n",
    "nn9_accuracy = round(100 * accuracy_score(Y_test, Y_pred), 2)\n",
    "model_performance['9 Nearest Neighbors'] = nn9_accuracy\n",
    "print('The accuracy of this model is {} %.'.format(nn9_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78e401a",
   "metadata": {},
   "source": [
    "##### 4.2.9 Applying K-Nearest Neighbors (11-NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8d5a3063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=11)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Applying 11NN model\n",
    "\n",
    "classifier_11nn = KNeighborsClassifier(n_neighbors = 11, algorithm = 'auto', p = 2, metric = 'minkowski')\n",
    "classifier_11nn.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a183d06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "### Predicting the Test set results\n",
    "\n",
    "Y_pred = classifier_11nn.predict(X_test)\n",
    "print(np.concatenate((Y_pred.reshape(len(Y_pred), 1), Y_test.reshape(len(Y_test), 1)), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1fe4b88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[68  1]\n",
      " [ 5 40]]\n",
      "The accuracy of this model is 94.74 %.\n"
     ]
    }
   ],
   "source": [
    "### Making the confusion matrix\n",
    "\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)\n",
    "\n",
    "### Printing the accuracy of the model\n",
    "\n",
    "nn11_accuracy = round(100 * accuracy_score(Y_test, Y_pred), 2)\n",
    "model_performance['11 Nearest Neighbors'] = nn11_accuracy\n",
    "print('The accuracy of this model is {} %.'.format(nn11_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d0435e",
   "metadata": {},
   "source": [
    "Now let's plot the accuracies of all the nearest neighbor models. We can see that the accuracy first increases, reaches a peak and then decreases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "21b54f63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Looking at the accuracy graph of all the nearest neighbors\n",
    "\n",
    "labels = ['1NN', '3NN', '5NN', '7NN', '9NN', '11NN']\n",
    "values = [nn1_accuracy, nn3_accuracy, nn5_accuracy, nn7_accuracy, nn9_accuracy, nn11_accuracy]\n",
    "\n",
    "plt.title('Accuracies of all the nearest neighbor models')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(labels, values, '*-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3345daf",
   "metadata": {},
   "source": [
    "##### 4.2.10 Applying Gaussian Naive Bayes Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d8507255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Applying Naive Bayes Classification model\n",
    "\n",
    "naive_bayes_classifier = GaussianNB()\n",
    "naive_bayes_classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c52f0574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "### Predicting the Test set results\n",
    "\n",
    "Y_pred = naive_bayes_classifier.predict(X_test)\n",
    "print(np.concatenate((Y_pred.reshape(len(Y_pred), 1), Y_test.reshape(len(Y_test), 1)), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "39f3eda3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[68  1]\n",
      " [ 4 41]]\n",
      "The accuracy of this model is 95.61 %.\n"
     ]
    }
   ],
   "source": [
    "### Making the confusion matrix\n",
    "\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)\n",
    "\n",
    "### Printing the accuracy of the model\n",
    "\n",
    "naive_bayes_accuracy = round(100 * accuracy_score(Y_test, Y_pred), 2)\n",
    "model_performance['Gaussian Naive Bayes'] = naive_bayes_accuracy\n",
    "print('The accuracy of this model is {} %.'.format(naive_bayes_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9261247c",
   "metadata": {},
   "source": [
    "##### 4.2.11 Applying Decision Tree Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5e538f30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', random_state=27)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Applying Decision Tree Classification model\n",
    "\n",
    "decision_tree_classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 27)\n",
    "decision_tree_classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8893aff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "### Predicting the Test set results\n",
    "\n",
    "Y_pred = decision_tree_classifier.predict(X_test)\n",
    "print(np.concatenate((Y_pred.reshape(len(Y_pred), 1), Y_test.reshape(len(Y_test), 1)), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fb0e00ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[63  6]\n",
      " [ 3 42]]\n",
      "The accuracy of this model is 92.11 %.\n"
     ]
    }
   ],
   "source": [
    "### Making the confusion matrix\n",
    "\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)\n",
    "\n",
    "### Printing the accuracy of the model\n",
    "\n",
    "decision_tree_accuracy = round(100 * accuracy_score(Y_test, Y_pred), 2)\n",
    "model_performance['Decision Tree'] = decision_tree_accuracy\n",
    "print('The accuracy of this model is {} %.'.format(decision_tree_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd561296",
   "metadata": {},
   "source": [
    "##### 4.2.12 Applying Random Forest Classification (10 trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "23c791a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', n_estimators=10, random_state=27)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Applying Random Forest Classification model (10 trees)\n",
    "\n",
    "random_forest_10_classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 27)\n",
    "random_forest_10_classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7c89045a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "### Predicting the Test set results\n",
    "\n",
    "Y_pred = random_forest_10_classifier.predict(X_test)\n",
    "print(np.concatenate((Y_pred.reshape(len(Y_pred), 1), Y_test.reshape(len(Y_test), 1)), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "59148b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[67  2]\n",
      " [ 4 41]]\n",
      "The accuracy of this model is 94.74 %.\n"
     ]
    }
   ],
   "source": [
    "### Making the confusion matrix\n",
    "\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)\n",
    "\n",
    "### Printing the accuracy of the model\n",
    "\n",
    "random_forest_10_accuracy = round(100 * accuracy_score(Y_test, Y_pred), 2)\n",
    "model_performance['Random Forest (10 trees)'] = random_forest_10_accuracy\n",
    "print('The accuracy of this model is {} %.'.format(random_forest_10_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221c5c4b",
   "metadata": {},
   "source": [
    "##### 4.2.13 Applying Random Forest Classification (25 trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "52f50bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', n_estimators=25, random_state=27)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Applying Random Forest Classification model (25 trees)\n",
    "\n",
    "random_forest_25_classifier = RandomForestClassifier(n_estimators = 25, criterion = 'entropy', random_state = 27)\n",
    "random_forest_25_classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bc981ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "### Predicting the Test set results\n",
    "\n",
    "Y_pred = random_forest_25_classifier.predict(X_test)\n",
    "print(np.concatenate((Y_pred.reshape(len(Y_pred), 1), Y_test.reshape(len(Y_test), 1)), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "894dcf5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[68  1]\n",
      " [ 3 42]]\n",
      "The accuracy of this model is 96.49 %.\n"
     ]
    }
   ],
   "source": [
    "### Making the confusion matrix\n",
    "\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)\n",
    "\n",
    "### Printing the accuracy of the model\n",
    "\n",
    "random_forest_25_accuracy = round(100 * accuracy_score(Y_test, Y_pred), 2)\n",
    "model_performance['Random Forest (25 trees)'] = random_forest_25_accuracy\n",
    "print('The accuracy of this model is {} %.'.format(random_forest_25_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35c40e9",
   "metadata": {},
   "source": [
    "##### 4.2.14 Applying Random Forest Classification (50 trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a1490be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', n_estimators=50, random_state=27)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Applying Random Forest Classification model (50 trees)\n",
    "\n",
    "random_forest_50_classifier = RandomForestClassifier(n_estimators = 50, criterion = 'entropy', random_state = 27)\n",
    "random_forest_50_classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "11ee90dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "### Predicting the Test set results\n",
    "\n",
    "Y_pred = random_forest_50_classifier.predict(X_test)\n",
    "print(np.concatenate((Y_pred.reshape(len(Y_pred), 1), Y_test.reshape(len(Y_test), 1)), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "27b35375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[67  2]\n",
      " [ 3 42]]\n",
      "The accuracy of this model is 95.61 %.\n"
     ]
    }
   ],
   "source": [
    "### Making the confusion matrix\n",
    "\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)\n",
    "\n",
    "### Printing the accuracy of the model\n",
    "\n",
    "random_forest_50_accuracy = round(100 * accuracy_score(Y_test, Y_pred), 2)\n",
    "model_performance['Random Forest (50 trees)'] = random_forest_50_accuracy\n",
    "print('The accuracy of this model is {} %.'.format(random_forest_50_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f5a5d8",
   "metadata": {},
   "source": [
    "##### 4.2.15 Applying Random Forest Classification (100 trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fa25224c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', random_state=27)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Applying Random Forest Classification model (100 trees)\n",
    "\n",
    "random_forest_100_classifier = RandomForestClassifier(n_estimators = 100, criterion = 'entropy', random_state = 27)\n",
    "random_forest_100_classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4299d0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "### Predicting the Test set results\n",
    "\n",
    "Y_pred = random_forest_100_classifier.predict(X_test)\n",
    "print(np.concatenate((Y_pred.reshape(len(Y_pred), 1), Y_test.reshape(len(Y_test), 1)), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "59ddbd5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[67  2]\n",
      " [ 3 42]]\n",
      "The accuracy of this model is 95.61 %.\n"
     ]
    }
   ],
   "source": [
    "### Making the confusion matrix\n",
    "\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)\n",
    "\n",
    "### Printing the accuracy of the model\n",
    "\n",
    "random_forest_100_accuracy = round(100 * accuracy_score(Y_test, Y_pred), 2)\n",
    "model_performance['Random Forest (100 trees)'] = random_forest_100_accuracy\n",
    "print('The accuracy of this model is {} %.'.format(random_forest_100_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b259f5",
   "metadata": {},
   "source": [
    "#### 4.3 Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19881f45",
   "metadata": {},
   "source": [
    "Model evaluation is the process of using different evaluation metrics to understand a machine learning model's performance, as well as its strengths and weaknesses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b12c27b",
   "metadata": {},
   "source": [
    "##### 4.3.1 Training accuracy of the models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac92aebc",
   "metadata": {},
   "source": [
    "Now we will tabulate all the models along with their accuracies. This data is stored in the model_performance dictionary. We will use the tabulate package for tabulating the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "36b48c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Logistic Regression', 97.37),\n",
       "             ('Linear SVC', 97.37),\n",
       "             ('Kernel SVC', 98.25),\n",
       "             ('1 Nearest Neighbors', 94.74),\n",
       "             ('3 Nearest Neighbors', 97.37),\n",
       "             ('5 Nearest Neighbors', 97.37),\n",
       "             ('7 Nearest Neighbors', 97.37),\n",
       "             ('9 Nearest Neighbors', 95.61),\n",
       "             ('11 Nearest Neighbors', 94.74),\n",
       "             ('Gaussian Naive Bayes', 95.61),\n",
       "             ('Decision Tree', 92.11),\n",
       "             ('Random Forest (10 trees)', 94.74),\n",
       "             ('Random Forest (25 trees)', 96.49),\n",
       "             ('Random Forest (50 trees)', 95.61),\n",
       "             ('Random Forest (100 trees)', 95.61)])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Looking at the model performance dictionary\n",
    "\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0b4f9fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═══════════════════════════╤══════════════════╕\n",
      "│   S.No. │ Classification Model      │   Model Accuracy │\n",
      "╞═════════╪═══════════════════════════╪══════════════════╡\n",
      "│       1 │ Logistic Regression       │            97.37 │\n",
      "├─────────┼───────────────────────────┼──────────────────┤\n",
      "│       2 │ Linear SVC                │            97.37 │\n",
      "├─────────┼───────────────────────────┼──────────────────┤\n",
      "│       3 │ Kernel SVC                │            98.25 │\n",
      "├─────────┼───────────────────────────┼──────────────────┤\n",
      "│       4 │ 1 Nearest Neighbors       │            94.74 │\n",
      "├─────────┼───────────────────────────┼──────────────────┤\n",
      "│       5 │ 3 Nearest Neighbors       │            97.37 │\n",
      "├─────────┼───────────────────────────┼──────────────────┤\n",
      "│       6 │ 5 Nearest Neighbors       │            97.37 │\n",
      "├─────────┼───────────────────────────┼──────────────────┤\n",
      "│       7 │ 7 Nearest Neighbors       │            97.37 │\n",
      "├─────────┼───────────────────────────┼──────────────────┤\n",
      "│       8 │ 9 Nearest Neighbors       │            95.61 │\n",
      "├─────────┼───────────────────────────┼──────────────────┤\n",
      "│       9 │ 11 Nearest Neighbors      │            94.74 │\n",
      "├─────────┼───────────────────────────┼──────────────────┤\n",
      "│      10 │ Gaussian Naive Bayes      │            95.61 │\n",
      "├─────────┼───────────────────────────┼──────────────────┤\n",
      "│      11 │ Decision Tree             │            92.11 │\n",
      "├─────────┼───────────────────────────┼──────────────────┤\n",
      "│      12 │ Random Forest (10 trees)  │            94.74 │\n",
      "├─────────┼───────────────────────────┼──────────────────┤\n",
      "│      13 │ Random Forest (25 trees)  │            96.49 │\n",
      "├─────────┼───────────────────────────┼──────────────────┤\n",
      "│      14 │ Random Forest (50 trees)  │            95.61 │\n",
      "├─────────┼───────────────────────────┼──────────────────┤\n",
      "│      15 │ Random Forest (100 trees) │            95.61 │\n",
      "╘═════════╧═══════════════════════════╧══════════════════╛\n"
     ]
    }
   ],
   "source": [
    "### Tabulating the results\n",
    "\n",
    "table = []\n",
    "table.append(['S.No.', 'Classification Model', 'Model Accuracy'])\n",
    "count = 1\n",
    "\n",
    "for model in model_performance:\n",
    "    row = [count, model, model_performance[model]]\n",
    "    table.append(row)\n",
    "    count += 1\n",
    "    \n",
    "print(tabulate(table, headers = 'firstrow', tablefmt = 'fancy_grid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0fca5c",
   "metadata": {},
   "source": [
    "From the above table, we can see that the model - Kernel Support Vector Classification has the highest accuracy of 98.25 %"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4abad30",
   "metadata": {},
   "source": [
    "##### 4.3.2 Applying K-fold Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230b6e08",
   "metadata": {},
   "source": [
    "It is important to not get too carried away with models with impressive training accuracy as what we should focus on instead is the model's ability to predict out-of-samples data, in other words, data our model has not seen before. This is where k-fold cross validation comes in. K-fold cross validation is a technique whereby a subset of our training set is kept aside and will act as holdout set for testing purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fd33b2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create a list of classifiers\n",
    "\n",
    "classifiers = []\n",
    "classifiers.append(logistic_classifier)\n",
    "classifiers.append(linear_svm_classifier)\n",
    "classifiers.append(kernel_svm_classifier)\n",
    "classifiers.append(classifier_1nn)\n",
    "classifiers.append(classifier_3nn)\n",
    "classifiers.append(classifier_5nn)\n",
    "classifiers.append(classifier_7nn)\n",
    "classifiers.append(classifier_9nn)\n",
    "classifiers.append(classifier_11nn)\n",
    "classifiers.append(naive_bayes_classifier)\n",
    "classifiers.append(decision_tree_classifier)\n",
    "classifiers.append(random_forest_10_classifier)\n",
    "classifiers.append(random_forest_25_classifier)\n",
    "classifiers.append(random_forest_50_classifier)\n",
    "classifiers.append(random_forest_100_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd53dff",
   "metadata": {},
   "source": [
    "We will now use this list of classifiers to perform K-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "88e46a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[96.51111111111112,\n",
       " 97.42222222222222,\n",
       " 97.37777777777778,\n",
       " 94.93333333333334,\n",
       " 96.93333333333334,\n",
       " 96.26666666666668,\n",
       " 96.93333333333334,\n",
       " 97.82222222222222,\n",
       " 97.60000000000001,\n",
       " 93.17777777777778,\n",
       " 92.53333333333332,\n",
       " 96.26666666666667,\n",
       " 95.82222222222222,\n",
       " 95.82222222222222,\n",
       " 96.48888888888888]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Applying K-fold cross validation and tabulating the results\n",
    "\n",
    "validation_accuracies = []\n",
    "standard_deviations = []\n",
    "\n",
    "for each_classifier in classifiers:\n",
    "    accuracy = cross_val_score(estimator = each_classifier, X = X_train, y = Y_train, cv = 50)\n",
    "    validation_accuracies.append(np.mean(accuracy) * 100)\n",
    "    standard_deviations.append(accuracy.std() * 100)\n",
    "    \n",
    "validation_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b46241a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═══════════════════════════╤══════════════════╤═══════════════════════╤══════════════════════╕\n",
      "│   S.No. │ Classification Model      │   Model Accuracy │   Validation Accuracy │   Standard Deviation │\n",
      "╞═════════╪═══════════════════════════╪══════════════════╪═══════════════════════╪══════════════════════╡\n",
      "│       1 │ Logistic Regression       │            97.37 │               96.5111 │              5.5556  │\n",
      "├─────────┼───────────────────────────┼──────────────────┼───────────────────────┼──────────────────────┤\n",
      "│       2 │ Linear SVC                │            97.37 │               97.4222 │              4.59436 │\n",
      "├─────────┼───────────────────────────┼──────────────────┼───────────────────────┼──────────────────────┤\n",
      "│       3 │ Kernel SVC                │            98.25 │               97.3778 │              5.17239 │\n",
      "├─────────┼───────────────────────────┼──────────────────┼───────────────────────┼──────────────────────┤\n",
      "│       4 │ 1 Nearest Neighbors       │            94.74 │               94.9333 │              7.40757 │\n",
      "├─────────┼───────────────────────────┼──────────────────┼───────────────────────┼──────────────────────┤\n",
      "│       5 │ 3 Nearest Neighbors       │            97.37 │               96.9333 │              5.83967 │\n",
      "├─────────┼───────────────────────────┼──────────────────┼───────────────────────┼──────────────────────┤\n",
      "│       6 │ 5 Nearest Neighbors       │            97.37 │               96.2667 │              6.08077 │\n",
      "├─────────┼───────────────────────────┼──────────────────┼───────────────────────┼──────────────────────┤\n",
      "│       7 │ 7 Nearest Neighbors       │            97.37 │               96.9333 │              4.92191 │\n",
      "├─────────┼───────────────────────────┼──────────────────┼───────────────────────┼──────────────────────┤\n",
      "│       8 │ 9 Nearest Neighbors       │            95.61 │               97.8222 │              4.36009 │\n",
      "├─────────┼───────────────────────────┼──────────────────┼───────────────────────┼──────────────────────┤\n",
      "│       9 │ 11 Nearest Neighbors      │            94.74 │               97.6    │              4.52352 │\n",
      "├─────────┼───────────────────────────┼──────────────────┼───────────────────────┼──────────────────────┤\n",
      "│      10 │ Gaussian Naive Bayes      │            95.61 │               93.1778 │              7.88814 │\n",
      "├─────────┼───────────────────────────┼──────────────────┼───────────────────────┼──────────────────────┤\n",
      "│      11 │ Decision Tree             │            92.11 │               92.5333 │              8.64681 │\n",
      "├─────────┼───────────────────────────┼──────────────────┼───────────────────────┼──────────────────────┤\n",
      "│      12 │ Random Forest (10 trees)  │            94.74 │               96.2667 │              5.66017 │\n",
      "├─────────┼───────────────────────────┼──────────────────┼───────────────────────┼──────────────────────┤\n",
      "│      13 │ Random Forest (25 trees)  │            96.49 │               95.8222 │              5.78444 │\n",
      "├─────────┼───────────────────────────┼──────────────────┼───────────────────────┼──────────────────────┤\n",
      "│      14 │ Random Forest (50 trees)  │            95.61 │               95.8222 │              6.19661 │\n",
      "├─────────┼───────────────────────────┼──────────────────┼───────────────────────┼──────────────────────┤\n",
      "│      15 │ Random Forest (100 trees) │            95.61 │               96.4889 │              5.58375 │\n",
      "╘═════════╧═══════════════════════════╧══════════════════╧═══════════════════════╧══════════════════════╛\n"
     ]
    }
   ],
   "source": [
    "### Tabulating the results\n",
    "\n",
    "table = []\n",
    "table.append(['S.No.', 'Classification Model', 'Model Accuracy', 'Validation Accuracy', 'Standard Deviation'])\n",
    "count = 1\n",
    "\n",
    "for model in model_performance:\n",
    "    row = [count, model, model_performance[model], validation_accuracies[count - 1], standard_deviations[count - 1]]\n",
    "    table.append(row)\n",
    "    count += 1\n",
    "    \n",
    "print(tabulate(table, headers = 'firstrow', tablefmt = 'fancy_grid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b4d21d",
   "metadata": {},
   "source": [
    "From the above table, we can see that the validation accuracy is higher in 9 Nearest Neighbors. However, on comparing the models - Kernel SVC and 9 Nearest Neighbors we can see that the Training accuracy and Validation accuracy is stable in Kernel SVC model (less standard deviation). Hence, we use the model Kernel SVC for Breast Cancer Detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d888d89e",
   "metadata": {},
   "source": [
    "### 5. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630802ab",
   "metadata": {},
   "source": [
    "Hence our recommended model - Kernel SVC provides a model accuracy of 98.25 percent and a validation accuracy of 97.38 percent. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
